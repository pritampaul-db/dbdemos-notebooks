{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e128487-c2e6-4ea0-b516-7732565b30d2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Data Setup\n",
    "\n",
    "We have the raw review content CSV for Boat products in volume. Which can be easily uploaded from UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daff6471-8d52-4f2a-8b81-045d13abf69f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Load Dataset\n",
    "boat=pd.read_csv('/Volumes/techsummit25/boat_reviews/raw_data/BoatProduct.csv')\n",
    "\n",
    "display(boat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2134f6d-8b7e-47eb-b74c-8387f95770b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "On the raw data we are doing some data clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ebd1dc7-f30c-4b16-b6f7-dcac0e156a6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning Price Column\n",
    "new = boat[\"ProductPrice\"].str.split(\" \", n = 1, expand = True)\n",
    "boat[\"Price\"]= new[1]\n",
    "boat['Price']=boat['Price'].str.replace('priceâ‚¹', '')\n",
    "boat['Price']=boat['Price'].str.replace(',', '').astype('float64')\n",
    "\n",
    "# Cleaning Discount Column\n",
    "new = boat[\"Discount\"].str.split(\" \", n = 1, expand = True)\n",
    "boat[\"Disc\"]= new[0]\n",
    "\n",
    "# Cleaning no of reviews column\n",
    "new = boat[\"NumberofReviews\"].str.split(\" \", n = 1, expand = True)\n",
    "boat[\"Review\"]= new[0]\n",
    "boat['Review']=boat['Review'].astype('category')\n",
    "boat['Review']=pd.to_numeric(boat['Review'],errors='coerce')\n",
    "\n",
    "# Cleaning Rate column\n",
    "new = boat[\"Rate\"].str.split(\" \", n = 1, expand = True)\n",
    "boat[\"Rate\"]= new[1]\n",
    "boat[\"Rate\"]=boat[\"Rate\"].astype('float64')\n",
    "\n",
    "# Dropping duplicate columns\n",
    "boat.drop([\"ProductPrice\",\"Discount\",\"NumberofReviews\"],axis=1,inplace=True)\n",
    "boat.head()\n",
    "\n",
    "display(boat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "666c812c-37e2-41f0-a940-5cd4ec1d2853",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Loading the raw data in a Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da5425e4-f50d-4632-a2ad-258fe9583813",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert pandas dataframe to spark dataframe\n",
    "boat_spark = spark.createDataFrame(boat)\n",
    "\n",
    "# Save the spark dataframe to a Delta table\n",
    "boat_spark.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"techsummit25.boat_reviews.boatproductdelta\")\n",
    "\n",
    "spark.sql(\"DELETE FROM techsummit25.boat_reviews.boatproductdelta WHERE ProductName = 'ProductName'\")\n",
    "\n",
    "# Display the Delta table\n",
    "display(spark.sql(\"SELECT * FROM techsummit25.boat_reviews.boatproductdelta\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8034d106-4c80-4430-907c-c5a2dcbdb37f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creating a SQL function to get the average number of reviews for a product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "432a3e8a-0e05-413e-baba-2aaab2c4c7a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION techsummit25.boat_reviews.avg_score(p STRING) RETURNS FLOAT\n",
    "    COMMENT 'Get the average number of reviews for a product'\n",
    "    RETURN SELECT round(AVG(Review)) FROM techsummit25.boat_reviews.boatproductdelta WHERE Lower(ProductName) like CONCAT('%', lower(p), '%');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7aa359a4-219e-497d-9d5c-da67e9f6d48b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creating a SQL function to get the review comments for a product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9378c628-68f3-4bd1-b379-3e22500ee774",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION techsummit25.boat_reviews.comments(p STRING) RETURNS TABLE (comments STRING)\n",
    "    COMMENT 'Get all review comments for a product'\n",
    "    RETURN SELECT summary FROM techsummit25.boat_reviews.boatproductdelta WHERE Lower(ProductName) like CONCAT('%', lower(p), '%');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cfd54a3-5778-406d-aa9a-80cc3c32b5f1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Agent Creation\n",
    "\n",
    "This part notebook created by an AI Playground export. \n",
    "\n",
    "This notebook uses Mosaic AI Agent Framework ([AWS](https://docs.databricks.com/en/generative-ai/retrieval-augmented-generation.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/retrieval-augmented-generation)) to recreate your agent from the AI Playground. It defines a LangChain agent that has access to the tools from the source Playground session.\n",
    "\n",
    "Use this notebook to iterate on and modify the agent. For example, you could add more tools or change the system prompt.\n",
    "\n",
    " **_NOTE:_**  This notebook uses LangChain, however AI Agent Framework is compatible with other agent frameworks like Pyfunc and LlamaIndex.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "654f72eb-9f6a-4031-917e-fac00326686f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq databricks-agents mlflow langchain==0.2.16 langchain_core langchain-community==0.2.16 langgraph==0.2.16 pydantic\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b6904c7-c0f3-44e6-a522-89c2a5603ef2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Import and setup\n",
    "\n",
    "Use `mlflow.langchain.autolog()` to set up [MLflow traces](https://docs.databricks.com/en/mlflow/mlflow-tracing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ad37434-8b2b-4a5b-ab9e-da51d58e5f46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import ModelConfig\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "config = ModelConfig(development_config=\"boat_agent_config.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24794a06-931b-4137-8ef2-193c1adf62cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Define the chat model and tools\n",
    "Create a LangChain chat model that supports [LangGraph tool](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/) calling.\n",
    "\n",
    "Modify the tools your agent has access to by modifying the `uc_functions` list in [config.yml]($./boat_agent_config.yml). Any non-UC function spec tools can be defined in this notebook. See [LangChain - How to create tools](https://python.langchain.com/v0.2/docs/how_to/custom_tools/) and [LangChain - Using built-in tools](https://python.langchain.com/v0.2/docs/how_to/tools_builtin/).\n",
    "\n",
    " **_NOTE:_**  This notebook uses LangChain, however AI Agent Framework is compatible with other agent frameworks like Pyfunc and LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6104cb5-5baa-445a-823b-360a3ba5961e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatDatabricks\n",
    "from langchain_community.tools.databricks import UCFunctionToolkit\n",
    "\n",
    "# Create the llm\n",
    "llm = ChatDatabricks(endpoint=config.get(\"llm_endpoint\"))\n",
    "\n",
    "uc_functions = config.get(\"uc_functions\")\n",
    "\n",
    "uc_function_tools = (\n",
    "    UCFunctionToolkit(warehouse_id=config.get(\"warehouse_id\"))\n",
    "    .include(*uc_functions)\n",
    "    .get_tools()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7236329d-fb44-41ea-8dba-68f56c2d0e40",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Output parsers\n",
    "Databricks interfaces, such as the AI Playground, can optionally display pretty-printed tool calls.\n",
    "\n",
    "Use the following helper functions to parse the LLM's output into the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12922082-9da8-43b7-a508-6ff9421703a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterator, Dict, Any\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    "    MessageLikeRepresentation,\n",
    ")\n",
    "\n",
    "import json\n",
    "\n",
    "uc_functions_set = {x.replace(\".\", \"__\") for x in uc_functions}\n",
    "\n",
    "\n",
    "def is_uc_function(tool_name: str) -> bool:\n",
    "    \"\"\"Check if `tool_name` is in `uc_functions` or belongs to a schema from config.yml.\"\"\"\n",
    "    if tool_name in uc_functions_set:\n",
    "        return True\n",
    "    for pattern in uc_functions_set:\n",
    "        if \"*\" in pattern and tool_name.startswith(pattern[:-1]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def stringify_tool_call(tool_call: Dict[str, Any]) -> str:\n",
    "    \"\"\"Convert a raw tool call into a formatted string that the playground UI expects\"\"\"\n",
    "    if is_uc_function(tool_call.get(\"name\")):\n",
    "        request = json.dumps(\n",
    "            {\n",
    "                \"id\": tool_call.get(\"id\"),\n",
    "                \"name\": tool_call.get(\"name\"),\n",
    "                \"arguments\": json.dumps(tool_call.get(\"args\", {})),\n",
    "            },\n",
    "            indent=2,\n",
    "        )\n",
    "        return f\"<uc_function_call>{request}</uc_function_call>\"\n",
    "    else:\n",
    "        # for non UC functions, return the string representation of tool calls\n",
    "        # you can modify this to return a different format\n",
    "        return str(tool_call)\n",
    "\n",
    "\n",
    "def stringify_tool_result(tool_msg: ToolMessage) -> str:\n",
    "    \"\"\"Convert a ToolMessage into a formatted string that the playground UI expects\"\"\"\n",
    "    if is_uc_function(tool_msg.name):\n",
    "        result = json.dumps(\n",
    "            {\"id\": tool_msg.tool_call_id, \"content\": tool_msg.content}, indent=2\n",
    "        )\n",
    "        return f\"<uc_function_result>{result}</uc_function_result>\"\n",
    "    else:\n",
    "        # for non UC functions, return the string representation of tool message\n",
    "        # you can modify this to return a different format\n",
    "        return str(tool_msg)\n",
    "\n",
    "\n",
    "def parse_message(msg) -> str:\n",
    "    \"\"\"Parse different message types into their string representations\"\"\"\n",
    "    # tool call result\n",
    "    if isinstance(msg, ToolMessage):\n",
    "        return stringify_tool_result(msg)\n",
    "    # tool call\n",
    "    elif isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "        tool_call_results = [stringify_tool_call(call) for call in msg.tool_calls]\n",
    "        return \"\".join(tool_call_results)\n",
    "    # normal HumanMessage or AIMessage (reasoning or final answer)\n",
    "    elif isinstance(msg, (AIMessage, HumanMessage)):\n",
    "        return msg.content\n",
    "    else:\n",
    "        print(f\"Unexpected message type: {type(msg)}\")\n",
    "        return str(msg)\n",
    "\n",
    "\n",
    "def wrap_output(stream: Iterator[MessageLikeRepresentation]) -> Iterator[str]:\n",
    "    \"\"\"\n",
    "    Process and yield formatted outputs from the message stream.\n",
    "    The invoke and stream langchain functions produce different output formats.\n",
    "    This function handles both cases.\n",
    "    \"\"\"\n",
    "    for event in stream:\n",
    "        # the agent was called with invoke()\n",
    "        if \"messages\" in event:\n",
    "            for msg in event[\"messages\"]:\n",
    "                yield parse_message(msg) + \"\\n\\n\"\n",
    "        # the agent was called with stream()\n",
    "        else:\n",
    "            for node in event:\n",
    "                for key, messages in event[node].items():\n",
    "                    if isinstance(messages, list):\n",
    "                        for msg in messages:\n",
    "                            yield parse_message(msg) + \"\\n\\n\"\n",
    "                    else:\n",
    "                        print(\"Unexpected value {messages} for key {key}. Expected a list of `MessageLikeRepresentation`'s\")\n",
    "                        yield str(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ab2c6fa-db6c-41ed-b9ae-f651c4362b0d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create the agent\n",
    "Use the LangGraph [`create_react_agent` function](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/#usage) to build a simple graph with the model and tools defined by [config.yml]($./boat_agent_config.yml). For more customization, you can create your own LangGraph agent by following [LangGraph - Quick Start](https://langchain-ai.github.io/langgraph/tutorials/introduction/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8079652-769d-4bd9-aab1-2ef0ee42dd6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableGenerator\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the agent\n",
    "system_message = config.get(\"agent_prompt\")\n",
    "agent_with_raw_output = create_react_agent(llm, uc_function_tools, state_modifier=system_message)\n",
    "agent = agent_with_raw_output | RunnableGenerator(wrap_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47a34ce6-30c7-43b9-ac27-922a9af8b0a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output. Since this notebook called `mlflow.langchain.autolog()` you can view the trace for each step the agent takes.\n",
    "\n",
    "Replace this placeholder input with an appropriate domain-specific example for your agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12c33c52-5329-4c67-a9ec-38e0ec56847d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Input example with an appropriate domain-specific example for your agent\n",
    "for event in agent.stream({\"messages\": [{\"role\": \"user\", \"content\": \"what is the total number of reviews for the product  Stone Grenade?\"}]}):\n",
    "    print(event, \"---\" * 20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08d134f0-cc0b-4386-a1d0-91a5be706689",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.set_model(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbe3aa04-54ec-436c-b1d8-b1482d51a101",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Log the `agent` as an MLflow model\n",
    "Log the agent as code from the [agent]($./agent) notebook. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "070127f5-0976-4840-b312-dccb6cae3fb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log the model to MLflow\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"what is the total number of reviews for the product Stone Grenade?\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.langchain.log_model(\n",
    "        lc_model=os.path.join(\n",
    "            os.getcwd(),\n",
    "            'boat_agent',\n",
    "        ),\n",
    "        pip_requirements=[\n",
    "            f\"langchain==0.2.16\",\n",
    "            f\"langchain-community==0.2.16\",\n",
    "            f\"langgraph==0.2.16\",\n",
    "            f\"pydantic\",\n",
    "        ],\n",
    "        model_config=\"boat_agent_config.yml\",\n",
    "        artifact_path='boat_agent',\n",
    "        input_example=input_example,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a37bbc3b-c534-45d1-89e2-cb702b1690e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with [Agent Evaluation](https://docs.databricks.com/generative-ai/agent-evaluation/index.html)\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b3893b6-2a7e-4c1b-9073-ff9edab58fee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eval_examples = [\n",
    "    {\n",
    "        \"request\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"what is the total number of reviews for the product Stone Grenade?\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": \"The average score for the product 'Stone Grenade' is 92.0.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "eval_dataset = pd.DataFrame(eval_examples)\n",
    "display(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0926dc8-aa11-4f01-94f3-1693a62c661d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "with mlflow.start_run(run_id=logged_agent_info.run_id):\n",
    "    eval_results = mlflow.evaluate(\n",
    "        f\"runs:/{logged_agent_info.run_id}/boat_agent\",  # replace `chain` with artifact_path that you used when calling log_model.\n",
    "        data=eval_dataset,  # Your evaluation dataset\n",
    "        model_type=\"databricks-agent\",  # Enable Mosaic AI Agent Evaluation\n",
    "    )\n",
    "\n",
    "# Review the evaluation results in the MLFLow UI (see console output), or access them in place:\n",
    "display(eval_results.tables['eval_results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1aada61-fbda-4eb3-83cb-a967544d61d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a2fff63-b495-4dba-ba86-ec0e08231669",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# define the catalog, schema, and model name for your UC model\n",
    "catalog = \"techsummit25\"\n",
    "schema = \"boat_reviews\"\n",
    "model_name = \"boat_agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33804c1d-f80a-428d-8f03-d14970948890",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7172d16c-757e-46c8-9716-bfd849c19327",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Deploy the model to the review app and a model serving endpoint\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4320825364204285,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "04_Boat_Review_Sentiment_Analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
